{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tune your preprocessing steps and algorithm selection like hyperparameters](https://medium.com/@moritzkoerber/tune-your-preprocessing-steps-and-algorithm-selection-like-hyperparameters-c817e6572335)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The various different preprocessing pipelines can be achieved by:\n",
    "\n",
    "1. Including a specific subset of the features\n",
    "2. Just for understanding, see how LabelEncoding should not be used as against OneHotEncoding\n",
    "3. Try OneHotEncoding v/s Ordinal encoding for ordinal variables\n",
    "4. Try continuous variables with or without binning/discretization\n",
    "5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T12:26:08.693638Z",
     "start_time": "2020-04-26T12:26:08.688152Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T17:45:34.791013Z",
     "start_time": "2020-04-25T17:45:34.760120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "df.drop('PassengerId', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T14:01:33.416278Z",
     "start_time": "2020-04-26T14:01:33.408021Z"
    }
   },
   "outputs": [],
   "source": [
    "df_X = df.drop('Survived', axis=1)\n",
    "df_y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T14:01:33.725625Z",
     "start_time": "2020-04-26T14:01:33.718928Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df_y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example creation of a preprocessing pipeline\n",
    "\n",
    "1. Drop Name, Ticket - requires Feature Engineering\n",
    "2. OneHotEncoder for Sex\n",
    "3. Drop Cabin - requires Feature Engineering/(?And Not Imputation)\n",
    "4. Impute Age with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T14:01:34.882193Z",
     "start_time": "2020-04-26T14:01:34.873187Z"
    }
   },
   "outputs": [],
   "source": [
    "trnsfrmr = ColumnTransformer([\n",
    "    ('imputer', SimpleImputer(), ['Age']),\n",
    "    ('ohe', OneHotEncoder(drop='first'), ['Sex', 'Embarked'])\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either start with creating a dataframe by \n",
    "- dropping 'Name', 'Ticket', and 'Cabin'\n",
    "- dropping rows corresponding to NA values in Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T14:01:36.086558Z",
     "start_time": "2020-04-26T14:01:36.058356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0       3    male  22.0      1      0   7.2500        S\n",
       "1       1  female  38.0      1      0  71.2833        C\n",
       "2       3  female  26.0      0      0   7.9250        S\n",
       "3       1  female  35.0      1      0  53.1000        S\n",
       "4       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_init = df_X.drop(['Name', 'Ticket', 'Cabin'], axis=1).loc[~df_X.Embarked.isna(), :]\n",
    "df_init.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then use the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T11:33:13.193626Z",
     "start_time": "2020-04-26T11:33:13.148092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.       ,  1.       ,  0.       , ...,  1.       ,  0.       ,\n",
       "         7.25     ],\n",
       "       [38.       ,  0.       ,  0.       , ...,  1.       ,  0.       ,\n",
       "        71.2833   ],\n",
       "       [26.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "         7.925    ],\n",
       "       ...,\n",
       "       [29.6420927,  0.       ,  0.       , ...,  1.       ,  2.       ,\n",
       "        23.45     ],\n",
       "       [26.       ,  1.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "        30.       ],\n",
       "       [32.       ,  1.       ,  1.       , ...,  0.       ,  0.       ,\n",
       "         7.75     ]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1 = trnsfrmr.fit_transform(df_init)\n",
    "res1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T11:32:51.935237Z",
     "start_time": "2020-04-26T11:32:51.931914Z"
    }
   },
   "source": [
    "Or you can just make a preprocess pipeline out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:21:55.454158Z",
     "start_time": "2020-04-26T13:21:55.440188Z"
    }
   },
   "outputs": [],
   "source": [
    "class ColumnDropper(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.drop(self.key, axis=1)\n",
    "    \n",
    "    \n",
    "class NaNDropper(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.nan_indices = X.loc[:, self.key].isna().any(axis=1) | y.isna()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if y is None:\n",
    "            return X.loc[~self.nan_indices]\n",
    "        else:\n",
    "            return X.loc[~self.nan_indices], y.loc[~self.nan_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:21:55.740312Z",
     "start_time": "2020-04-26T13:21:55.729772Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocess = Pipeline([\n",
    "    ('clmn_dropper', ColumnDropper(['Name', 'Ticket', 'Cabin'])),\n",
    "    ('nan_dropper', NaNDropper(['Embarked'])),\n",
    "    ('trnsfrmr', trnsfrmr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:21:56.213061Z",
     "start_time": "2020-04-26T13:21:56.188287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.       ,  1.       ,  0.       , ...,  1.       ,  0.       ,\n",
       "         7.25     ],\n",
       "       [38.       ,  0.       ,  0.       , ...,  1.       ,  0.       ,\n",
       "        71.2833   ],\n",
       "       [26.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "         7.925    ],\n",
       "       ...,\n",
       "       [29.6420927,  0.       ,  0.       , ...,  1.       ,  2.       ,\n",
       "        23.45     ],\n",
       "       [26.       ,  1.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "        30.       ],\n",
       "       [32.       ,  1.       ,  1.       , ...,  0.       ,  0.       ,\n",
       "         7.75     ]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = preprocess.fit_transform(df_X, df_y)\n",
    "res2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the results we got were the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T11:33:46.692885Z",
     "start_time": "2020-04-26T11:33:46.685968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(res1, res2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T12:56:43.661041Z",
     "start_time": "2020-04-26T12:56:43.642582Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "('preprocess', preprocess),\n",
    "('clf', KNeighborsClassifier(5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T12:56:44.451343Z",
     "start_time": "2020-04-26T12:56:44.355454Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [889, 891]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-ad719c0ded08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ds/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    350\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    351\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ds/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \"\"\"\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ds/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ds/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [889, 891]"
     ]
    }
   ],
   "source": [
    "pipe.fit(df_X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But Bad Luck :(, since we changed the sample size by dropping the NaN rows, the input and output variables had inconsistent sizes. See the following links on the issue:\n",
    "\n",
    "- https://github.com/scikit-learn/scikit-learn/issues/3855\n",
    "- https://stackoverflow.com/questions/25539311/custom-transformer-for-sklearn-pipeline-that-alters-both-x-and-y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping in mind the above issue, this is how our general workflow will look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:02:08.701607Z",
     "start_time": "2020-04-26T13:02:08.689436Z"
    }
   },
   "outputs": [],
   "source": [
    "class AutoFitTrans:\n",
    "    '''\n",
    "    Use this to implement fit\n",
    "    '''\n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self):\n",
    "        pass\n",
    "    \n",
    "    def fit_transform(self, *args, **kwargs):\n",
    "        return self.fit(*args, **kwargs).transform(*args, **kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T15:26:02.307754Z",
     "start_time": "2020-04-26T15:26:02.299759Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Can I implement this to support both dataframes and arrays?\n",
    "# TODO: Implement key='auto' to drop all NaNs\n",
    "class NaNDropper(BaseEstimator, ClassifierMixin, AutoFitTrans):\n",
    "    \n",
    "    '''Drops rows with NaN values\n",
    "    \n",
    "    key: list-like\n",
    "        A list of keys(column names) to consider while dropping NaN values\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        '''Fits the model and extracts indices with missing values\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        X: pd.DataFrame\n",
    "        y: pd.Series (Default: None)\n",
    "        '''\n",
    "        \n",
    "        self.nan_indices = X.loc[:, self.key].isna().any(axis=1) | y.isna()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if y is None:\n",
    "            return X.loc[~self.nan_indices]\n",
    "        else:\n",
    "            return X.loc[~self.nan_indices], y.loc[~self.nan_indices]\n",
    "        \n",
    "#     def fit_transform(self, X, y=None):\n",
    "#         return self.fit(X, y).transform(X, y)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T15:26:08.477341Z",
     "start_time": "2020-04-26T15:26:08.454515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889, 10) (889,)\n"
     ]
    }
   ],
   "source": [
    "# Do any sample size altering steps before the pipeline\n",
    "\n",
    "preprocess_pre = Pipeline([\n",
    "    ('nan_dropper', NaNDropper(['Embarked']))])\n",
    "\n",
    "df_pre_X, df_pre_y = preprocess_pre.fit_transform(df_X, df_y)\n",
    "\n",
    "print(df_pre_X.shape, df_pre_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T19:28:11.715025Z",
     "start_time": "2020-04-26T19:28:11.665283Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocess',\n",
       "                 Pipeline(memory=None,\n",
       "                          steps=[('clmn_dropper',\n",
       "                                  ColumnDropper(key=['Name', 'Ticket',\n",
       "                                                     'Cabin'])),\n",
       "                                 ('trnsfrmr',\n",
       "                                  ColumnTransformer(n_jobs=None,\n",
       "                                                    remainder='passthrough',\n",
       "                                                    sparse_threshold=0.3,\n",
       "                                                    transformer_weights=None,\n",
       "                                                    transformers=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 st...\n",
       "                                                                                 verbose=0),\n",
       "                                                                   ['Age']),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(categories='auto',\n",
       "                                                                                 drop='first',\n",
       "                                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                                 handle_unknown='error',\n",
       "                                                                                 sparse=True),\n",
       "                                                                   ['Sex',\n",
       "                                                                    'Embarked'])],\n",
       "                                                    verbose=False))],\n",
       "                          verbose=False)),\n",
       "                ('clf',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=5, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now define the preprocessing step\n",
    "\n",
    "trnsfrmr = ColumnTransformer([\n",
    "    ('imputer', SimpleImputer(), ['Age']),\n",
    "    ('ohe', OneHotEncoder(drop='first'), ['Sex', 'Embarked'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "preprocess = Pipeline([\n",
    "    ('clmn_dropper', ColumnDropper(['Name', 'Ticket', 'Cabin'])),\n",
    "    ('trnsfrmr', trnsfrmr)\n",
    "])\n",
    "\n",
    "\n",
    "# Now define the whole pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocess', preprocess),\n",
    "    ('clf', KNeighborsClassifier(5))\n",
    "])\n",
    "\n",
    "# Now fit\n",
    "pipe.fit(df_pre_X, df_pre_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila! Everything works! :D <br/>\n",
    "These are the further things we can explore:\n",
    "1. Hyperparameter tuning for the preprocessing step which changes sample size\n",
    "2. Hyperparameter tuning for the sklearn pipeline compatible preprocessing step\n",
    "3. Hyperparameter tuning for the ML model\n",
    "4. Try various different pipelines\n",
    "\n",
    "\n",
    "\n",
    "I think implementing the following structure may help in efficiently using pipelines: <br/>\n",
    "Implement a class for each WHOLE pipeline which implements the following methods:\n",
    "1. preprocess_pre - preprocessing step which changes sample size\n",
    "2. preprocess - sklearn pipeline compatible preprocessing step\n",
    "3. pipe - The pipeline containing step 2. and ML model fitting\n",
    "4. description - The description of the pipeline in natural language\n",
    "\n",
    "Ofcourse each of these steps will be implemented and placed in a module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:58:51.618732Z",
     "start_time": "2020-04-26T13:58:51.606201Z"
    }
   },
   "source": [
    "Note: Instead of making a different pipelines for each combination we need to properly identify how we can just different combinations by specifying different hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a pipeline with a specific hyperparameter combination. <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T15:52:06.343843Z",
     "start_time": "2020-04-26T15:52:06.311571Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {'nan_dropper__key': ['Age', 'Embarked']}\n",
    "preprocess_pre.set_params(**params)\n",
    "df_pre_X, df_pre_y = preprocess_pre.fit_transform(df_X, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T15:52:08.570744Z",
     "start_time": "2020-04-26T15:52:08.556462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age         False\n",
       "Embarked    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre_X.loc[:, ['Age', 'Embarked']].isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it's verified we dropped the NaNs in our Age & Embarked column. We can other tests as well to see if it worked correctly or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for the preprocessing step.<br/>\n",
    "First let's take a look at the names of these params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T15:52:10.323708Z",
     "start_time": "2020-04-26T15:52:10.315452Z"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import PrettyPrinter\n",
    "pp = PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T15:52:10.795678Z",
     "start_time": "2020-04-26T15:52:10.765494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['memory',\n",
      " 'steps',\n",
      " 'verbose',\n",
      " 'clmn_dropper',\n",
      " 'trnsfrmr',\n",
      " 'clmn_dropper__key',\n",
      " 'trnsfrmr__n_jobs',\n",
      " 'trnsfrmr__remainder',\n",
      " 'trnsfrmr__sparse_threshold',\n",
      " 'trnsfrmr__transformer_weights',\n",
      " 'trnsfrmr__transformers',\n",
      " 'trnsfrmr__verbose',\n",
      " 'trnsfrmr__imputer',\n",
      " 'trnsfrmr__ohe',\n",
      " 'trnsfrmr__imputer__add_indicator',\n",
      " 'trnsfrmr__imputer__copy',\n",
      " 'trnsfrmr__imputer__fill_value',\n",
      " 'trnsfrmr__imputer__missing_values',\n",
      " 'trnsfrmr__imputer__strategy',\n",
      " 'trnsfrmr__imputer__verbose',\n",
      " 'trnsfrmr__ohe__categories',\n",
      " 'trnsfrmr__ohe__drop',\n",
      " 'trnsfrmr__ohe__dtype',\n",
      " 'trnsfrmr__ohe__handle_unknown',\n",
      " 'trnsfrmr__ohe__sparse']\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(list(preprocess.get_params().keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above will tell us the hyperparameters we can access. Sadly this doesn't include the columns. So we can create a Modded ColumnTransformer that will rectify and include columns as an argument in the \\_\\_init\\_\\_ signature, and therefore in the hyperparameters. \n",
    "\n",
    "But this has a problem, I can copy the init signature by using \\*args, \\*\\*kwargs but sklearn would throw a RunTimeError if all the keyword arguments aren't included explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T18:09:41.663268Z",
     "start_time": "2020-04-26T18:09:41.651056Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_ModTrnsfrmr(cls):\n",
    "    class ModTrnsfrmr(cls, AutoFitTrans): \n",
    "\n",
    "        def __init__(self, cols, *args, **kwargs):\n",
    "            self.__orig = super().__init__(*args, **kwargs)\n",
    "            self.cols = cols\n",
    "            \n",
    "        def fit(self, X, y=None):\n",
    "            return self.__orig.fit(X.loc[:, self.cols], y)\n",
    "            \n",
    "        def transform(self, ):\n",
    "            return self.__orig.transform(X.loc[:, self.cols])\n",
    "            \n",
    "                    \n",
    "    return ModTrnsfrmr\n",
    "        \n",
    "\n",
    "class ClmnTrnsfrmr(ColumnTransformer):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.__make_attrs()\n",
    "        \n",
    "    \n",
    "    def __make_attrs(self):\n",
    "        for i, (name, trnsfrmr, cols) in enumerate(self.transformers):\n",
    "            ModTrnsfrmr = make_ModTrnsfrmr(trnsfrmr.__class__)\n",
    "            modtrnsfrmr = ModTrnsfrmr(cols, **trnsfrmr.get_params())\n",
    "            self.transformers[i] = (name, modtrnsfrmr, cols)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative way is to just create another transformer instance from the ColumnTransformer and create a new preprocess pipeline based on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function to modify the columns in our old column transformer instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T20:15:21.910042Z",
     "start_time": "2020-04-26T20:15:21.890711Z"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def modify_transformer_cols(col_trnsfrmr: ColumnTransformer, append=False, **trnsfrmr_cols):\n",
    "    new_col_trnsfrmr = deepcopy(col_trnsfrmr)\n",
    "    trnsfrmrs = new_col_trnsfrmr.transformers\n",
    "    for i, [trnsfrmr_name, old_trnsfrmr, old_cols] in enumerate(trnsfrmrs):\n",
    "        new_cols = trnsfrmr_cols.get(trnsfrmr_name, None)\n",
    "        \n",
    "        if new_cols is not None:\n",
    "            if append:\n",
    "                new_cols  = list(set().union(new_cols, old_cols))\n",
    "        else:\n",
    "            new_cols = old_cols\n",
    "                            \n",
    "        trnsfrmrs[i] = (trnsfrmr_name, old_trnsfrmr, new_cols)\n",
    "        \n",
    "    return new_col_trnsfrmr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was our old column transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our modified column trnsfrmr with the following modifications:\n",
    "1. OneHotEncoding for Pclass in addition to Sex, Embarked (by setting append=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T20:23:03.022829Z",
     "start_time": "2020-04-26T20:23:02.994906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(n_jobs=None, remainder='passthrough', sparse_threshold=0.3,\n",
       "                  transformer_weights=None,\n",
       "                  transformers=[('imputer',\n",
       "                                 SimpleImputer(add_indicator=False, copy=True,\n",
       "                                               fill_value=None,\n",
       "                                               missing_values=nan,\n",
       "                                               strategy='mean', verbose=0),\n",
       "                                 ['Age']),\n",
       "                                ('ohe',\n",
       "                                 OneHotEncoder(categories='auto', drop='first',\n",
       "                                               dtype=<class 'numpy.float64'>,\n",
       "                                               handle_unknown='error',\n",
       "                                               sparse=True),\n",
       "                                 ['Sex', 'Embarked', 'Pclass'])],\n",
       "                  verbose=False)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trnsfrmr_mod = modify_transformer_cols(trnsfrmr, append=True, ohe=['Pclass'])\n",
    "trnsfrmr_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was our old preprocess pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T20:26:57.291272Z",
     "start_time": "2020-04-26T20:26:57.261419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('clmn_dropper',\n",
       "                 ColumnDropper(key=['Name', 'Ticket', 'Cabin'])),\n",
       "                ('trnsfrmr',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('imputer',\n",
       "                                                  SimpleImputer(add_indicator=False,\n",
       "                                                                copy=True,\n",
       "                                                                fill_value=None,\n",
       "                                                                missing_values=nan,\n",
       "                                                                strategy='mean',\n",
       "                                                                verbose=0),\n",
       "                                                  ['Age']),\n",
       "                                                 ('ohe',\n",
       "                                                  OneHotEncoder(categories='auto',\n",
       "                                                                drop='first',\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                sparse=True),\n",
       "                                                  ['Sex', 'Embarked'])],\n",
       "                                   verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can include this change in our preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T20:27:32.139926Z",
     "start_time": "2020-04-26T20:27:32.119291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('clmn_dropper',\n",
       "                 ColumnDropper(key=['Name', 'Ticket', 'Cabin'])),\n",
       "                ('trnsfrmr',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('imputer',\n",
       "                                                  SimpleImputer(add_indicator=False,\n",
       "                                                                copy=True,\n",
       "                                                                fill_value=None,\n",
       "                                                                missing_values=nan,\n",
       "                                                                strategy='mean',\n",
       "                                                                verbose=0),\n",
       "                                                  ['Age']),\n",
       "                                                 ('ohe',\n",
       "                                                  OneHotEncoder(categories='auto',\n",
       "                                                                drop='first',\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                sparse=True),\n",
       "                                                  ['Sex', 'Embarked',\n",
       "                                                   'Pclass'])],\n",
       "                                   verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess.set_params(trnsfrmr=trnsfrmr_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T20:30:25.456480Z",
     "start_time": "2020-04-26T20:30:25.427776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.    ,  1.    ,  0.    , ...,  1.    ,  0.    ,  7.25  ],\n",
       "       [38.    ,  0.    ,  0.    , ...,  1.    ,  0.    , 71.2833],\n",
       "       [26.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  7.925 ],\n",
       "       ...,\n",
       "       [19.    ,  0.    ,  0.    , ...,  0.    ,  0.    , 30.    ],\n",
       "       [26.    ,  1.    ,  0.    , ...,  0.    ,  0.    , 30.    ],\n",
       "       [32.    ,  1.    ,  1.    , ...,  0.    ,  0.    ,  7.75  ]])"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess.fit_transform(df_pre_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works! :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But ideally we would want to do it for the whole pipeline together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T20:33:58.409862Z",
     "start_time": "2020-04-26T20:33:58.394437Z"
    }
   },
   "outputs": [],
   "source": [
    "# preprocess pipeline\n",
    "\n",
    "preprocess = Pipeline([\n",
    "    ('clmn_dropper', ColumnDropper(['Name', 'Ticket', 'Cabin'])),\n",
    "    ('trnsfrmr', trnsfrmr)\n",
    "])\n",
    "\n",
    "# whole pipeline (sklearn compatible)\n",
    "pipe = Pipeline([\n",
    "    ('preprocess', preprocess),\n",
    "    ('clf', KNeighborsClassifier(5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T20:34:51.318732Z",
     "start_time": "2020-04-26T20:34:51.281043Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocess',\n",
       "                 Pipeline(memory=None,\n",
       "                          steps=[('clmn_dropper',\n",
       "                                  ColumnDropper(key=['Name', 'Ticket',\n",
       "                                                     'Cabin'])),\n",
       "                                 ('trnsfrmr',\n",
       "                                  ColumnTransformer(n_jobs=None,\n",
       "                                                    remainder='passthrough',\n",
       "                                                    sparse_threshold=0.3,\n",
       "                                                    transformer_weights=None,\n",
       "                                                    transformers=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 st...\n",
       "                                                                                 verbose=0),\n",
       "                                                                   ['Age']),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(categories='auto',\n",
       "                                                                                 drop='first',\n",
       "                                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                                 handle_unknown='error',\n",
       "                                                                                 sparse=True),\n",
       "                                                                   ['Sex',\n",
       "                                                                    'Embarked'])],\n",
       "                                                    verbose=False))],\n",
       "                          verbose=False)),\n",
       "                ('clf',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=5, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T20:35:04.736929Z",
     "start_time": "2020-04-26T20:35:04.699932Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocess',\n",
       "                 Pipeline(memory=None,\n",
       "                          steps=[('clmn_dropper',\n",
       "                                  ColumnDropper(key=['Name', 'Ticket',\n",
       "                                                     'Cabin'])),\n",
       "                                 ('trnsfrmr',\n",
       "                                  ColumnTransformer(n_jobs=None,\n",
       "                                                    remainder='passthrough',\n",
       "                                                    sparse_threshold=0.3,\n",
       "                                                    transformer_weights=None,\n",
       "                                                    transformers=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 st...\n",
       "                                                                   ['Age']),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(categories='auto',\n",
       "                                                                                 drop='first',\n",
       "                                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                                 handle_unknown='error',\n",
       "                                                                                 sparse=True),\n",
       "                                                                   ['Sex',\n",
       "                                                                    'Embarked',\n",
       "                                                                    'Pclass'])],\n",
       "                                                    verbose=False))],\n",
       "                          verbose=False)),\n",
       "                ('clf',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=5, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.set_params(preprocess__trnsfrmr=trnsfrmr_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T20:36:12.958703Z",
     "start_time": "2020-04-26T20:36:12.898059Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocess',\n",
       "                 Pipeline(memory=None,\n",
       "                          steps=[('clmn_dropper',\n",
       "                                  ColumnDropper(key=['Name', 'Ticket',\n",
       "                                                     'Cabin'])),\n",
       "                                 ('trnsfrmr',\n",
       "                                  ColumnTransformer(n_jobs=None,\n",
       "                                                    remainder='passthrough',\n",
       "                                                    sparse_threshold=0.3,\n",
       "                                                    transformer_weights=None,\n",
       "                                                    transformers=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 st...\n",
       "                                                                   ['Age']),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(categories='auto',\n",
       "                                                                                 drop='first',\n",
       "                                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                                 handle_unknown='error',\n",
       "                                                                                 sparse=True),\n",
       "                                                                   ['Sex',\n",
       "                                                                    'Embarked',\n",
       "                                                                    'Pclass'])],\n",
       "                                                    verbose=False))],\n",
       "                          verbose=False)),\n",
       "                ('clf',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=5, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(df_pre_X, df_pre_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ds] *",
   "language": "python",
   "name": "conda-env-ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
